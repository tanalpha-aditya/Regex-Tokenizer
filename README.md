# Regex-Tokenizer
A self made Regex Tokeniser to clean the corpus. 

For tokenization and cleaning I used the following embeddings :
•	Lower case
•	Hashtag
•	Mentions
•	Num
•	Currency
•	Url
•	Percentage
•	Punctuations 
•	Removing extra spaces
•	Removal of ‘/n’
